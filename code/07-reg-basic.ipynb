{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"07-reg-basic.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP2WxVI4rcv2kn77O9PJwgr"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"p-ZZF7_h7YBm"},"source":["import tensorflow as tf\n","tf.__version__"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6i7lxT-J7dSz"},"source":["활성화 함수"]},{"cell_type":"code","metadata":{"id":"BdNbyAHi7ebP"},"source":["import numpy as np\n","import matplotlib.pylab as plt\n","\n","def sigm_func(x): # sigmoid 함수\n","    return 1 / (1 + np.exp(-x))\n","\n","# 시그모이드 함수 그리기\n","plt.figure(figsize=(8, 6)) \n","x = np.linspace(-8, 8, 100)\n","plt.plot(x, sigm_func(x), 'b--')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dT0YQBc7hh0"},"source":["np.e"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QOtkQLnl7kBi"},"source":["plt.figure(figsize=(6, 4)) \n","x = np.linspace(-8, 8, 100)\n","plt.plot(x, np.exp(-x), 'b--')\n","_ = plt.plot(x, np.exp(x), 'r-.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NoLu9RX07lkO"},"source":["import numpy as np\n","import matplotlib.pylab as plt\n","\n","def relu_func(x): # ReLU(Rectified Linear Unit, 정류된 선형 유닛) 함수\n","    return np.maximum(0, x) \n","    #return (x>0)*x # same\n","\n","# ReLU 함수 그리기\n","plt.figure(figsize=(8, 6)) \n","x = np.linspace(-8, 8, 100)\n","plt.plot(x, relu_func(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjcTy_0R7oUB"},"source":["import numpy as np\n","import matplotlib.pylab as plt\n","\n","def relu_func(x): # ReLU(Rectified Linear Unit, 정류된 선형 유닛) 함수\n","    return np.maximum(0, x) \n","    #return (x>0)*x # same\n","\n","def sigm_func(x): # sigmoid 함수\n","    return 1 / (1 + np.exp(-x))\n","\n","# 그래프 그리기\n","plt.figure(figsize=(8, 6)) \n","x = np.linspace(-4, 4, 100)\n","y = np.linspace(-0.2, 2, 100)\n","\n","plt.plot(x, relu_func(x), linestyle=':', label=\"ReLU\")\n","plt.plot(x, sigm_func(x), linestyle='--', label=\"sigmoid\")\n","plt.legend(loc='upper left')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w2vtBji27qci"},"source":["import numpy as np\n","import matplotlib.pylab as plt\n"," \n","def identity_func(x): # 항등함수\n","    return x\n","  \n","def linear_func(x): # 1차함수\n","    return 1.5 * x + 1 # a기울기(1.5), Y절편b(1) 조정가능\n","\n","def tanh_func(x): # TanH 함수\n","    return np.tanh(x)\n","\n","def relu_func(x): # ReLU(Rectified Linear Unit, 정류된 선형 유닛) 함수\n","    return np.maximum(0, x) \n","    #return (x>0)*x # same\n","\n","def sigm_func(x): # sigmoid 함수\n","    return 1 / (1 + np.exp(-x))\n","\n","# 그래프 그리기\n","plt.figure(figsize=(12, 8)) \n","x = np.linspace(-4, 4, 100)\n","\n","plt.plot(x, identity_func(x), linestyle='--', label=\"identity\")\n","plt.plot(x, linear_func(x), linestyle=':', label=\"linear\")\n","plt.plot(x, tanh_func(x), linestyle='-.', label=\"tanh\")\n","plt.plot(x, relu_func(x), linestyle='-', label=\"ReLU\")\n","plt.plot(x, sigm_func(x), linestyle='--', label=\"sigmoid\")\n","plt.legend(loc='upper left')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A8_d9ppZ7sZy"},"source":["케라스로 구현하는 선형 회귀"]},{"cell_type":"code","metadata":{"id":"JcefNz_R7tE_"},"source":["import tensorflow as tf\n","\n","# ① 문제와 정답 데이터 지정\n","x_train = [1, 2, 3, 4]\n","y_train = [2, 4, 6, 8]\n","\n","# ② 모델 구성(생성)\n","model = tf.keras.models.Sequential([\n","    #                   출력, 입력=(*, 1)           그대로 출력\n","    tf.keras.layers.Dense(1, input_shape=(1, ), activation='linear')\n","    #Dense(1, input_dim=1)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVNvj5Xc7vtP"},"source":["# ③ 학습에 필요한 최적화 방법과 손실 함수 등 지정\n","# 훈련에 사용할 옵티마이저(optimizer)와 손실 함수, 출력 정보를 지정\n","# Mean Absolute Error, Mean Squared Error\n","model.compile(optimizer='SGD', loss='mse',\n","              metrics=['mae', 'mse'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9FdiMKLZ7z2u"},"source":["# 모델을 표시(시각화)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Xo_bRoI71oY"},"source":["# ④ 생성된 모델로 훈련 데이터 학습\n","# 훈련과정 정보를 history 객체에 저장 \n","history = model.fit(x_train, y_train, epochs=500)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FqId5EO274K-"},"source":["# ⑤ 테스트 데이터로 성능 평가\n","x_test = [1.2, 2.3, 3.4, 4.5]\n","y_test = [2.4, 4.6, 6.8, 9.0]\n","\n","print('손실:', model.evaluate(x_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRngZ9Z676Cu"},"source":["# x = [3.5, 5, 5.5, 6]의 예측 \n","print(model.predict([3.5, 5, 5.5, 6]))\n","\n","pred = model.predict([3.5, 5, 5.5, 6])\n","# 예측 값만 1차원으로 \n","print(pred.flatten())\n","print(pred.squeeze())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nWHQLBCu779v"},"source":["손실과 예측 시각화"]},{"cell_type":"code","metadata":{"id":"u9Zrhi2t79Ke"},"source":["history_dict = history.history\n","history_dict.keys()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E42krjA_8Aro"},"source":["import matplotlib.pylab as plt\n","\n","# 그래프 그리기\n","fig = plt.figure(figsize=(8, 6)) \n","\n","plt.plot(history.history['loss'], label='loss')\n","plt.plot(history.history['mae'], label='mae')\n","#plt.plot(history.history['mse'], label='mse')\n","\n","plt.legend(loc='best')\n","plt.xlabel('epoch')\n","plt.ylabel('loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rmpMe6P8CwO"},"source":["import matplotlib.pylab as plt\n","\n","x_test = [1.2, 2.3, 3.4, 4.5, 6.0]\n","y_test = [2.4, 4.6, 6.8, 9.0, 12.0]\n","\n","# 그래프 그리기\n","fig = plt.figure(figsize=(8, 6)) \n","\n","plt.scatter(x_test, y_test, label='label')\n","plt.plot(x_test, y_test, 'y--')\n","\n","x = [2.9, 3.5, 4.2, 5, 5.5, 6]\n","pred = model.predict(x)\n","plt.scatter(x, pred.flatten(), label='prediction')\n","\n","plt.legend(loc='best')\n","plt.xlabel('x')\n","plt.ylabel('y')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"chNInjOd8ER2"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YKsdd45E8F1x"},"source":["\n","#from keras.models import Sequential\n","#from keras.layers import Dense\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# ① 문제와 정답 데이터 지정\n","x_train = [1, 2, 3, 4]\n","y_train = [2, 4, 6, 8]\n","\n","# ② 모델 구성(생성)\n","model = Sequential([\n","    Dense(1, input_shape=(1, ), activation='linear')\n","    #Dense(1, input_dim=1)\n","])\n","\n","# ③ 학습에 필요한 최적화 방법과 손실 함수 등 지정\n","# 훈련에 사용할 옵티마이저(optimizer)와 손실 함수, 출력정보를 선택\n","# Mean Absolute Error, Mean Squared Error\n","model.compile(optimizer='SGD', loss='mse',\n","              metrics=['mae', 'mse'])\n","\n","# 모델을 표시(시각화)\n","model.summary()\n","\n","# ④ 생성된 모델로 훈련 데이터 학습\n","model.fit(x_train, y_train, epochs=1000)\n","\n","# ⑤ 테스트 데이터로 성능 평가\n","x_test = [1.2, 2.3, 3.4, 4.5]\n","y_test = [2.4, 4.6, 6.8, 9.0]\n","\n","print('정확도:', model.evaluate(x_test, y_test))\n","\n","print(model.predict([3.5, 5, 5.5, 6]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m9kMr21S8Jfl"},"source":["y = 2x + 1 예측"]},{"cell_type":"code","metadata":{"id":"DsUQcBL58K_u"},"source":["import tensorflow as tf\n","import numpy as np\n","\n","#훈련과 테스트 데이터\n","x = np.array([0, 1, 2, 3, 4])\n","y = np.array([1, 3, 5, 7, 9]) #y = x * 2 + 1\n","\n","#인공신경망 모델 사용\n","model = tf.keras.models.Sequential()\n","\n","#은닉계층 하나 추가 \n","model.add(tf.keras.layers.Dense(1, input_shape=(1,)))\n","\n","#모델의 패라미터를 지정하고 모델 구조를 생성\n","#최적화 알고리즘: 확률적 경사 하강법(SGD: Stochastic Gradient Descent)\n","#손실 함수(loss function): 평균제곱오차(MSE: Mean Square Error)  \n","model.compile('SGD', 'mse')\n","\n","#생성된 모델로 훈련 자료로 입력(x[:2])과 출력(y[:2])을 사용하여 학습\n","#키워드 매개변수 epoch(에퐄): 훈련반복횟수\n","#키워드 매개변수 verbose: 학습진행사항 표시\n","model.fit(x[:3], y[:3], epochs=1000, verbose=0)\n","\n","#테스트 자료의 결과를 출력\n","print('Targets(정답):', y[3:])\n","\n","#학습된 모델로 테스트 자료로 결과를 예측(model.predict)하여 출력\n","print('Predictions(예측):', model.predict(x[3:]).flatten())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_JI65ki98NLG"},"source":["\n","텐서플로로만 구현하는 선형 회귀 예제"]},{"cell_type":"code","metadata":{"id":"HQvGq7ZE8OqO"},"source":["import tensorflow as tf\n","# ① 문제와 정답 데이터 지정\n","x_train = [1, 2, 3, 4]\n","y_train = [2, 4, 6, 8]\n","\n","# ② 모델 구성(생성)\n","# 선형회귀 모델(Wx + b)을 위한 tf.Variable을 선언합니다.\n","W = tf.Variable(tf.random.normal(shape=[1]))\n","b = tf.Variable(tf.random.normal(shape=[1]))\n","\n","@tf.function\n","def linear_model(x):\n","    return W*x + b\n","\n","# ③ 학습에 필요한 최적화 방법과 손실 함수 등 지정\n","# 최적화를 위한 그라디언트 디센트 옵티마이저를 정의합니다.\n","optimizer = tf.optimizers.SGD(0.01)\n","\n","# 손실 함수를 정의합니다. MSE 손실함수 \\mean{(y' - y)^2}\n","@tf.function\n","def mse_loss(y_pred, y):\n","    return tf.reduce_mean(tf.square(y_pred - y))\n","\n","# ④ 생성된 모델로 훈련 데이터 학습\n","# 최적화를 위한 function을 정의합니다.\n","@tf.function\n","def train_step(x, y):\n","    with tf.GradientTape() as tape:\n","        y_pred = linear_model(x) # 모델에 위한 예측 값 계산\n","        loss = mse_loss(y_pred, y) # MSE 손실 계산\n","    gradients = tape.gradient(loss, [W, b]) # 미분 자동계산\n","    optimizer.apply_gradients(zip(gradients, [W, b])) # 최적화 과정에 적용\n","\n","# 경사하강법을 1000번 수행합니다.\n","for i in range(1000):\n","    train_step(x_train, y_train)\n","\n","# ⑤ 테스트 데이터로 성능 평가\n","x_test = [3.5, 5, 5.5, 6]\n","\n","# 테스트 데이터를 이용해 학습된 선형회귀 모델이 데이터의 경향성(y=2x)을 잘 학습했는지 측정합니다.\n","# 예상되는 참값 : [7, 10, 11, 12]\n","print(linear_model(x_test).numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zunkeF8R8SLG"},"source":["import tensorflow as tf\n","\n","x = tf.ones((2, 2))\n","\n","with tf.GradientTape() as t:\n","    t.watch(x)\n","    y = tf.reduce_sum(x)\n","    z = tf.multiply(y, y)\n","\n","# 입력 텐서 x에 대한 z의 도함수\n","dz_dx = t.gradient(z, x)\n","for i in [0, 1]:\n","    for j in [0, 1]:\n","        assert dz_dx[i][j].numpy() == 8.0"],"execution_count":null,"outputs":[]}]}